(ns machine-learning-clojure.linear-regresion
  (:use [clojure.core.matrix :only [column-count row-count transpose inverse]]
        [incanter.charts :only [scatter-plot add-lines xy-plot]]
        [incanter.core   :only [view sel to-matrix bind-columns]]
        [incanter.stats :only [linear-model]]
        [incanter.datasets :only [get-dataset]])
  (:require [clatrix.core :as cl]
            [clojure.core.matrix.operators :as M]))

;; Examples from
;; Clojure for Machine Learning
;; by Akhil Wali

;; Chapter 2. Understanding Linear Regression

(def X (cl/matrix [8.401 14.475 13.396 12.127 5.044
                   8.339 15.692 17.108 9.253 12.029]))

(def Y (cl/matrix [-1.57 2.32  0.424  0.814 -2.3
                   0.01 1.954 2.296 -0.635 0.328]))

(def linear-samp-scatter
  (scatter-plot X Y))

(defn plot-scatter []
  (view linear-samp-scatter))

#_(plot-scatter) 

;; using incanter's ordinary-least squares (OLS) curve-fitting algorithm

(def samp-linear-model
  (linear-model Y X))

(comment
  linear-samp-scatter

  samp-linear-model

  ;;theta coeficients
  (:coefs samp-linear-model)

  ;;overall deviation of the model from the given data
  (:residuals samp-linear-model)

  ;;sum of squared errors of prediction (SSE)
  (:sse samp-linear-model)

  ;;mean-squared error (MSE)
  (:mse samp-linear-model)

  ;;root mean-squared error (RMSE) or root-mean squared deviation
  (Math/sqrt (:mse samp-linear-model))

  ;;coefficient of determination
  (:r-square samp-linear-model)
  ;; In order to formulate a model that best fits the sample data,
  ;; we should strive to minimize the previously described values

  ;;cost function

  )

(defn plot-model []
  (view (add-lines linear-samp-scatter
                   X (:fitted samp-linear-model))))

#_(plot-model)

(def gradient-descent-precision 0.001)

(defn gradient-descent
  "Find the local minimum of the cost function's plot"
  [F' x-start step]
  (loop [x-old x-start]
    (let [x-new (- x-old
                   (* step (F' x-old)))
          dx (- x-new x-old)]
      (if (< dx gradient-descent-precision)
        x-new
        (recur x-new)))))

(def iris
  (to-matrix (get-dataset :iris)))

(def X (sel iris :cols (range 1 5)))
(def Y (sel iris :cols 0))

(def iris-linear-model
  (linear-model Y X))
(defn plot-iris-linear-model []
  (let [x (range -100 100)
        y (:fitted iris-linear-model)]
    (view (xy-plot x y :x-label "X" :y-label "Y"))))

#_(plot-iris-linear-model)

(comment
  (= (count (:coefs iris-linear-model)) 
     (+ 1 (column-count X)))

  )

(defn linear-model-ols
  "Estimates the coefficients of a multi-var linear
  regression model using Ordinary Least Squares (OLS) method"
  [MX MY]
  (let [X (bind-columns (repeat (row-count MX) 1) MX)
        Xt (cl/matrix (transpose X))
        Xt-X (cl/* Xt X)]
    (cl/* (inverse Xt-X) Xt MY)))

(def ols-linear-model
  (linear-model-ols X Y))

(def ols-linear-model-coefs
  (cl/as-vec ols-linear-model))

(comment
  (cl/as-vec ols-linear-model)

  (:coefs iris-linear-model)

  ;; coefficients estimated by the ols-linear-model function
  ;; practically identical to
  ;; the ones generated by the Incanter library's linear-model function
  (every? #(< % 0.0001)
          (map -
               ols-linear-model-coefs
               (:coefs iris-linear-model)))

  )


(defn predict [coefs X]
  {:pre [(= (count coefs)
            (+ 1 (count X)))]}
  (let [X-with-1 (conj X 1)
        products (map * coefs X-with-1)]
    (reduce + products)))


;; Regularization
;; technique to provide a better fit for the data

;; underfit or high bias
;; it doesn't estimate the dependent variable to a value that is close to the observed values
;;  has a significant error, or rather deviation, with respect to the actual data


;; overfit or high variance
;; estimated model fits the data perfectly, but isn't general enough to be useful for prediction

;; Tikhnov regularization or ridge regression

